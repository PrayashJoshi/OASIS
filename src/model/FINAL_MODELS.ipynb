{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d56c09a",
   "metadata": {},
   "source": [
    "# CS 4824 - Machine Learning\n",
    "The following contains all of our baseline comparison metrics and our developed metrics for hierarchical agglomerative clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5137c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries for import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import operator\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd38573",
   "metadata": {},
   "source": [
    "## Open the necessary files for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7417df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce619ec5",
   "metadata": {},
   "source": [
    "## Centroid Link\n",
    "The following creates a hierarchical agglomerative clustering of the above data based upon the centroid link metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc94c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_distance(c1, c2):\n",
    "    return math.sqrt((c2[1]-c1[1])**2+(c2[0]-c1[0])**2)\n",
    "\n",
    "def find_min_clusters(clusters):\n",
    "    curr_cluster_1 = 0\n",
    "    curr_cluster_2 = 1\n",
    "    curr_dist = -1\n",
    "    for i in range(0, len(clusters)):\n",
    "        for y in range(i+1, len(clusters)):\n",
    "            new_dist = cluster_distance(clusters[i], clusters[y])\n",
    "            if curr_dist < 0 or curr_dist > cluster_distance(clusters[i], clusters[y]):\n",
    "                curr_cluster_1 = i\n",
    "                curr_cluster_2 = y\n",
    "                curr_dist = cluster_distance(clusters[i], clusters[y])\n",
    "    return curr_cluster_1, curr_cluster_2, curr_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f883a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_clustering_linkage(df):\n",
    "    # linkage used for dendrogram drawing\n",
    "    linkage = []\n",
    "    \n",
    "    # List of current elements, in their x and y dimensions, zipped together\n",
    "    curr_x = [x for x in df.iloc[:,0]]\n",
    "    curr_y = [y for y in df.iloc[:,1]]\n",
    "    curr_clusters = [list(c) for c in zip(curr_x, curr_y)]\n",
    "    \n",
    "    # Indices of current clusters\n",
    "    idxs = [i for i in normalized_df.index]\n",
    "    \n",
    "    # The number of items in each cluster\n",
    "    items_per_cluster = [1 for i in range(0, len(curr_x))]\n",
    "\n",
    "    while len(curr_clusters) > 1:\n",
    "        # Get cluster indices and distances\n",
    "        c1, c2, curr_dist = find_min_clusters(curr_clusters)\n",
    "        \n",
    "        # Specify new cluster centroids\n",
    "        new_c = []\n",
    "        new_c.append((curr_clusters[c1][0] + curr_clusters[c2][0])/2)\n",
    "        new_c.append((curr_clusters[c1][1] + curr_clusters[c2][1])/2)\n",
    "        \n",
    "        # Remove old clusters from the set of current clusters\n",
    "        curr_clusters.pop(c1)\n",
    "        curr_clusters.pop(c2-1)\n",
    "        \n",
    "        # Increment for new cluster\n",
    "        idxs.append(idxs[-1] + 1)\n",
    "        \n",
    "        # Add new cluster to list of clusters\n",
    "        curr_clusters.append(new_c)\n",
    "        \n",
    "        # Update number of items per cluster, removing old ones and adding in new one\n",
    "        num_items = items_per_cluster[c1] + items_per_cluster[c2]\n",
    "        items_per_cluster.pop(c1)\n",
    "        items_per_cluster.pop(c2-1)\n",
    "        items_per_cluster.append(num_items)\n",
    "        \n",
    "        # Add new iteraion to linkage\n",
    "        linkage.append([idxs[c1], idxs[c2], curr_dist, num_items])\n",
    "        \n",
    "        # Remove old cluster indices\n",
    "        idxs.pop(c1)\n",
    "        idxs.pop(c2-1)\n",
    "    \n",
    "    return linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e9055c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalized_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0151dc143982>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Determine linkage of centroid link model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcentroid_link_linkage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhierarchical_clustering_linkage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m pd.DataFrame(linkage, \n\u001b[0;32m      4\u001b[0m              \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'row label 1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'row label 2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'distance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'no. of items in clust.'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m              index=['cluster %d' %(i+1) for i in range(len(centroid_link_linkage))])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalized_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Determine linkage of centroid link model\n",
    "centroid_link_linkage = hierarchical_clustering_linkage(normalized_df)\n",
    "pd.DataFrame(centroid_link_linkage, \n",
    "             columns=['row label 1', 'row label 2', 'distance', 'no. of items in clust.'],\n",
    "             index=['cluster %d' %(i+1) for i in range(len(centroid_link_linkage))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909089ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [i for i in normalized_df.index]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "row_dendr = dendrogram(centroid_link_linkage, labels=indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050551ec",
   "metadata": {},
   "source": [
    "## Single Link\n",
    "The following creates a hierarchical agglomerative clustering of the above data based upon the single link metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59da0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_clusters_single_link(clusters, elements_in_clusters):\n",
    "    curr_cluster_1 = 0\n",
    "    curr_cluster_2 = 1\n",
    "    curr_dist = -1\n",
    "    for i in range(0, len(clusters)):\n",
    "        for y in range(i+1, len(clusters)):\n",
    "            for x in range(0, len(elements_in_clusters[i])):\n",
    "                for z in range(0, len(elements_in_clusters[y])):\n",
    "                    new_dist = cluster_distance(elements_in_clusters[i][x], elements_in_clusters[y][z])\n",
    "                    if curr_dist < 0 or curr_dist > new_dist:\n",
    "                        curr_cluster_1 = i\n",
    "                        curr_cluster_2 = y\n",
    "                        curr_dist = new_dist\n",
    "    return curr_cluster_1, curr_cluster_2, curr_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53ac8609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_clustering_linkage_single_link(df):\n",
    "    # linkage used for dendrogram drawing\n",
    "    linkage = []\n",
    "    \n",
    "    # List of current elements, in their x and y dimensions, zipped together\n",
    "    curr_x = [x for x in df.iloc[:,0]]\n",
    "    curr_y = [y for y in df.iloc[:,1]]\n",
    "    curr_clusters = [list(c) for c in zip(curr_x, curr_y)]\n",
    "    elements_in_clusters = [[list(c)] for c in zip(curr_x, curr_y)]\n",
    "    \n",
    "    # Indices of current clusters\n",
    "    idxs = [i for i in normalized_df.index]\n",
    "    \n",
    "    # The number of items in each cluster\n",
    "    items_per_cluster = [1 for i in range(0, len(curr_x))]\n",
    "\n",
    "    while len(curr_clusters) > 1:\n",
    "        # Get cluster indices and distances\n",
    "        c1, c2, curr_dist = find_min_clusters_single_link(curr_clusters, elements_in_clusters)\n",
    "        new_clst_elem = elements_in_clusters[c1] + elements_in_clusters[c2]\n",
    "        elements_in_clusters.pop(c1)\n",
    "        elements_in_clusters.pop(c2-1)\n",
    "        elements_in_clusters.append(new_clst_elem)\n",
    "        \n",
    "        # Specify new cluster centroids\n",
    "        new_c = []\n",
    "        new_c.append((curr_clusters[c1][0] + curr_clusters[c2][0])/2)\n",
    "        new_c.append((curr_clusters[c1][1] + curr_clusters[c2][1])/2)\n",
    "        \n",
    "        # Remove old clusters from the set of current clusters\n",
    "        curr_clusters.pop(c1)\n",
    "        curr_clusters.pop(c2-1)\n",
    "        \n",
    "        # Increment for new cluster\n",
    "        idxs.append(idxs[-1] + 1)\n",
    "        \n",
    "        # Add new cluster to list of clusters\n",
    "        curr_clusters.append(new_c)\n",
    "        \n",
    "        # Update number of items per cluster, removing old ones and adding in new one\n",
    "        num_items = items_per_cluster[c1] + items_per_cluster[c2]\n",
    "        items_per_cluster.pop(c1)\n",
    "        items_per_cluster.pop(c2-1)\n",
    "        items_per_cluster.append(num_items)\n",
    "        \n",
    "        # Add new iteraion to linkage\n",
    "        linkage.append([idxs[c1], idxs[c2], curr_dist, num_items])\n",
    "        \n",
    "        # Remove old cluster indices\n",
    "        idxs.pop(c1)\n",
    "        idxs.pop(c2-1)\n",
    "    \n",
    "    return linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_link_linkage = hierarchical_clustering_linkage_single_link(normalized_df)\n",
    "pd.DataFrame(single_link_linkage, \n",
    "             columns=['row label 1', 'row label 2', 'distance', 'no. of items in clust.'],\n",
    "             index=['cluster %d' %(i+1) for i in range(len(single_link_linkage))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 10))\n",
    "row_dendr = dendrogram(single_link_linkage, labels=indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189cb74",
   "metadata": {},
   "source": [
    "## Complete Link\n",
    "The following creates a hierarchical agglomerative clustering of the above data based upon the complete link metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5b431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_clusters_complete_link(clusters, elements_in_clusters):\n",
    "    curr_cluster_1 = 0\n",
    "    curr_cluster_2 = 1\n",
    "    curr_dist = -1\n",
    "    for i in range(0, len(clusters)):\n",
    "        for y in range(i+1, len(clusters)):\n",
    "            curr_group_dist = -1\n",
    "            for x in range(0, len(elements_in_clusters[i])):\n",
    "                for z in range(0, len(elements_in_clusters[y])):\n",
    "                    new_dist = cluster_distance_complete_link(elements_in_clusters[i][x], elements_in_clusters[y][z])\n",
    "                    if curr_group_dist <= new_dist:\n",
    "                        curr_group_dist = new_dist\n",
    "            if curr_dist < 0 or (curr_dist > curr_group_dist and curr_group_dist > -1):\n",
    "                        curr_cluster_1 = i\n",
    "                        curr_cluster_2 = y\n",
    "                        curr_dist = curr_group_dist\n",
    "    return curr_cluster_1, curr_cluster_2, curr_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f51cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_clustering_linkage_complete_link(df):\n",
    "    # linkage used for dendrogram drawing\n",
    "    linkage = []\n",
    "    \n",
    "    # List of current elements, in their x and y dimensions, zipped together\n",
    "    curr_x = [x for x in df.iloc[:,0]]\n",
    "    curr_y = [y for y in df.iloc[:,1]]\n",
    "    curr_clusters = [list(c) for c in zip(curr_x, curr_y)]\n",
    "    elements_in_clusters = [[list(c)] for c in zip(curr_x, curr_y)]\n",
    "    \n",
    "    # Indices of current clusters\n",
    "    idxs = [i for i in normalized_df.index]\n",
    "    \n",
    "    # The number of items in each cluster\n",
    "    items_per_cluster = [1 for i in range(0, len(curr_x))]\n",
    "\n",
    "    while len(curr_clusters) > 1:\n",
    "        # Get cluster indices and distances\n",
    "        c1, c2, curr_dist = find_min_clusters_complete_link(curr_clusters, elements_in_clusters)\n",
    "        new_clst_elem = elements_in_clusters[c1] + elements_in_clusters[c2]\n",
    "        elements_in_clusters.pop(c1)\n",
    "        elements_in_clusters.pop(c2-1)\n",
    "        elements_in_clusters.append(new_clst_elem)\n",
    "        \n",
    "        # Specify new cluster centroids\n",
    "        new_c = []\n",
    "        new_c.append((curr_clusters[c1][0] + curr_clusters[c2][0])/2)\n",
    "        new_c.append((curr_clusters[c1][1] + curr_clusters[c2][1])/2)\n",
    "        \n",
    "        # Remove old clusters from the set of current clusters\n",
    "        curr_clusters.pop(c1)\n",
    "        curr_clusters.pop(c2-1)\n",
    "        \n",
    "        # Increment for new cluster\n",
    "        idxs.append(idxs[-1] + 1)\n",
    "        \n",
    "        # Add new cluster to list of clusters\n",
    "        curr_clusters.append(new_c)\n",
    "        \n",
    "        # Update number of items per cluster, removing old ones and adding in new one\n",
    "        num_items = items_per_cluster[c1] + items_per_cluster[c2]\n",
    "        items_per_cluster.pop(c1)\n",
    "        items_per_cluster.pop(c2-1)\n",
    "        items_per_cluster.append(num_items)\n",
    "        \n",
    "        # Add new iteraion to linkage\n",
    "        linkage.append([idxs[c1], idxs[c2], curr_dist, num_items])\n",
    "        \n",
    "        # Remove old cluster indices\n",
    "        idxs.pop(c1)\n",
    "        idxs.pop(c2-1)\n",
    "    \n",
    "    return linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b92793",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_link_linkage = hierarchical_clustering_linkage_complete_link(normalized_df)\n",
    "pd.DataFrame(complete_link_linkage, \n",
    "             columns=['row label 1', 'row label 2', 'distance', 'no. of items in clust.'],\n",
    "             index=['cluster %d' %(i+1) for i in range(len(complete_link_linkage))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 10))\n",
    "row_dendr = dendrogram(complete_link_linkage, labels=indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0cebcf",
   "metadata": {},
   "source": [
    "## Fuzzy Membership Matrix\n",
    "The following calculates a hierarchical agglomerative clustering of the above data using our fuzzy membership matrix metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d04f67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_membership_matrix(n, k):\n",
    "    membership_mat = []\n",
    "    for i in range(n):\n",
    "        random_num_list = [random.random() for _ in range(k)]\n",
    "        summation = sum(random_num_list)\n",
    "        temp_list = [x / summation for x in random_num_list]\n",
    "        membership_mat.append(temp_list)\n",
    "    return membership_mat\n",
    "\n",
    "# Update membership values based on the cluster centers\n",
    "def update_membership_values(membership_mat, cluster_centers, df, m, k):\n",
    "    p = float(2 / (m - 1))\n",
    "    for i in range(len(df)):\n",
    "        x = list(df.iloc[i])\n",
    "        distances = [np.linalg.norm(list(map(operator.sub, x, cluster_centers[j]))) for j in range(k)]\n",
    "        for j in range(k):\n",
    "            den = sum([math.pow(distances[j] / distances[c], p) for c in range(k) if distances[c] != 0])\n",
    "            membership_mat[i][j] = float(1 / den) if den != 0 else 0\n",
    "    return membership_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a694ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_clustering_linkage_fuzzy_membership_matrix(normalized_df):\n",
    "    df_cpy = normalized_df[:50].copy(deep=True)\n",
    "    fuzzy_linkage = []\n",
    "    curr_x = [x for x in df_cpy.iloc[:,0]]\n",
    "    curr_y = [y for y in df_cpy.iloc[:,1]]\n",
    "    curr_clusters = [list(c) for c in zip(curr_x, curr_y)]\n",
    "    idxs = [i for i in df_cpy.index]\n",
    "    items_per_cluster = [1 for i in range(0, len(curr_x))]\n",
    "    m = 2.00\n",
    "    n = len(df_cpy)\n",
    "    k = len(curr_clusters)\n",
    "    mat = initialize_membership_matrix(n, k)\n",
    "\n",
    "    while len(curr_clusters) > 1:\n",
    "        n = len(df_cpy)\n",
    "        k = len(curr_clusters)\n",
    "\n",
    "        mat = initialize_membership_matrix(n, k)\n",
    "        mat = update_membership_values(mat, curr_clusters, df_cpy, m, k)\n",
    "        for m in range(0, len(mat)):\n",
    "            mat[m][m] = 100\n",
    "            \n",
    "        new_clusters = np.argwhere(mat == np.amin(mat))[0]\n",
    "        c1 = new_clusters[0]\n",
    "        c2 = new_clusters[1]\n",
    "        curr_dist = np.amin(mat)\n",
    "        print(f\"c1 {c1} c2 {c2} curr dist {curr_dist}\")\n",
    "\n",
    "        # Specify new cluster centroids\n",
    "        new_c = []\n",
    "        new_c.append((curr_clusters[c1][0] + curr_clusters[c2][0])/2)\n",
    "        new_c.append((curr_clusters[c1][1] + curr_clusters[c2][1])/2)\n",
    "\n",
    "        # Remove old clusters from the set of current clusters\n",
    "        curr_clusters.pop(c1)\n",
    "        curr_clusters.pop(c2-1)\n",
    "\n",
    "        # Drop old elements in dataframe\n",
    "        df_cpy = df_cpy.drop([c1, c2])\n",
    "        df_cpy = df_cpy.reset_index(drop=True)\n",
    "\n",
    "        # Add in new cluster to dataframe\n",
    "        df_cpy.loc[len(df_cpy)] = new_c\n",
    "\n",
    "        # Increment for new cluster\n",
    "        idxs.append(idxs[-1] + 1)\n",
    "\n",
    "        # Add new cluster to list of clusters\n",
    "        curr_clusters.append(new_c)\n",
    "\n",
    "        # Update number of items per cluster, removing old ones and adding in new one\n",
    "        num_items = items_per_cluster[c1] + items_per_cluster[c2]\n",
    "        items_per_cluster.pop(c1)\n",
    "        items_per_cluster.pop(c2-1)\n",
    "        items_per_cluster.append(num_items)\n",
    "\n",
    "        # Add new iteraion to linkage\n",
    "        fuzzy_linkage.append([idxs[c1], idxs[c2], curr_dist, num_items])\n",
    "\n",
    "        # Remove old cluster indices\n",
    "        if c2 > c1:\n",
    "            idxs.pop(c1)\n",
    "            idxs.pop(c2-1)\n",
    "        else:\n",
    "            idxs.pop(c2)\n",
    "            idxs.pop(c1-1)\n",
    "            \n",
    "    return fuzzy_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_membership_matrix_fuzzy_linkage = hierarchical_clustering_linkage_fuzzy_membership_matrix(normalized_df)\n",
    "flpd = pd.DataFrame(fuzzy_membership_matrix_fuzzy_linkage, \n",
    "             columns=['row label 1', 'row label 2', 'distance', 'no. of items in clust.'],\n",
    "             index=['cluster %d' %(i+1) for i in range(len(fuzzy_membership_matrix_fuzzy_linkage))])\n",
    "flpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 10))\n",
    "row_dendr = dendrogram(fuzzy_membership_matrix_fuzzy_linkage, labels=`indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc21a88",
   "metadata": {},
   "source": [
    "## Naive Weighted Fuzzy Membership Matrix\n",
    "The following calculates a hierarchical agglomerative clustering of the above data using our naive weighted fuzzy membership matrix metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53809eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_clustering_linkage_naive_weighted_fuzzy_membership_matrix(normalized_df):\n",
    "    df_cpy = normalized_df[:50].copy(deep=True)\n",
    "    fuzzy_linkage = []\n",
    "    curr_x = [x for x in df_cpy.iloc[:,0]]\n",
    "    curr_y = [y for y in df_cpy.iloc[:,1]]\n",
    "    curr_clusters = [list(c) for c in zip(curr_x, curr_y)]\n",
    "    idxs = [i for i in df_cpy.index]\n",
    "    items_per_cluster = [1 for i in range(0, len(curr_x))]\n",
    "    m = 2.00\n",
    "    n = len(df_cpy)\n",
    "    k = len(curr_clusters)\n",
    "    v = [np.std(normalized_df.iloc[:,i]) / np.average(normalized_df.iloc[:,i]) for i in range(0, len(normalized_df.columns))]\n",
    "    w = [v[i] / sum(v) for i in range(0, len(v))]\n",
    "    mat = initialize_membership_matrix(n, k)\n",
    "\n",
    "    while len(curr_clusters) > 1:\n",
    "        n = len(df_cpy)\n",
    "        k = len(curr_clusters)\n",
    "\n",
    "        mat = initialize_membership_matrix(n, k)\n",
    "        mat = update_membership_values_weighted(mat, curr_clusters, df_cpy, m, k, w)\n",
    "        for m in range(0, len(mat)):\n",
    "            mat[m][m] = 100\n",
    "        new_clusters = np.argwhere(mat == np.amin(mat))[0]\n",
    "        c1 = new_clusters[0]\n",
    "        c2 = new_clusters[1]\n",
    "        curr_dist = np.amin(mat)\n",
    "        print(f\"k {k} c1 {c1} c2 {c2} curr dist {curr_dist}\")\n",
    "\n",
    "        # Specify new cluster centroids\n",
    "        new_c = []\n",
    "        new_c.append((curr_clusters[c1][0] + curr_clusters[c2][0])/2)\n",
    "        new_c.append((curr_clusters[c1][1] + curr_clusters[c2][1])/2)\n",
    "\n",
    "        # Remove old clusters from the set of current clusters\n",
    "        curr_clusters.pop(c1)\n",
    "        curr_clusters.pop(c2-1)\n",
    "\n",
    "        # Drop old elements in dataframe\n",
    "        df_cpy = df_cpy.drop([c1, c2])\n",
    "        df_cpy = df_cpy.reset_index(drop=True)\n",
    "\n",
    "        # Add in new cluster to dataframe\n",
    "        df_cpy.loc[len(df_cpy)] = new_c\n",
    "\n",
    "        # Increment for new cluster\n",
    "        idxs.append(idxs[-1] + 1)\n",
    "\n",
    "        # Add new cluster to list of clusters\n",
    "        curr_clusters.append(new_c)\n",
    "\n",
    "        # Update number of items per cluster, removing old ones and adding in new one\n",
    "        num_items = items_per_cluster[c1] + items_per_cluster[c2]\n",
    "        items_per_cluster.pop(c1)\n",
    "        items_per_cluster.pop(c2-1)\n",
    "        items_per_cluster.append(num_items)\n",
    "\n",
    "        # Add new iteraion to linkage\n",
    "        fuzzy_linkage.append([idxs[c1], idxs[c2], curr_dist, num_items])\n",
    "\n",
    "        # Remove old cluster indices\n",
    "        if c2 > c1:\n",
    "            idxs.pop(c1)\n",
    "            idxs.pop(c2-1)\n",
    "        else:\n",
    "            idxs.pop(c2)\n",
    "            idxs.pop(c1-1)\n",
    "            \n",
    "    return fuzzy_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf47d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_weighted_fuzzy_linkage = hierarchical_clustering_linkage_naive_weighted_fuzzy_membership_matrix(normalized_df)\n",
    "tpd = pd.DataFrame(naive_weighted_fuzzy_linkage, \n",
    "             columns=['row label 1', 'row label 2', 'distance', 'no. of items in clust.'],\n",
    "             index=['cluster %d' %(i+1) for i in range(len(naive_weighted_fuzzy_linkage))])\n",
    "tpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 10))\n",
    "row_dendr = dendrogram(naive_weighted_fuzzy_linkage, labels=indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca3795",
   "metadata": {},
   "source": [
    "## Entropy Weight Measure Weighted Fuzzy Membership Matrix\n",
    "The following calculates a hierarchical agglomerative clustering of the above data using our entropy weight measure weighted fuzzy membership matrix metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "149df55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_clustering_linkage_ewm_weighted_fuzzy_membership_matrix(clusters):\n",
    "    df_cpy = normalized_df[:50].copy(deep=True)\n",
    "    fuzzy_linkage = []\n",
    "    curr_x = [x for x in df_cpy.iloc[:,0]]\n",
    "    curr_y = [y for y in df_cpy.iloc[:,1]]\n",
    "    curr_clusters = [list(c) for c in zip(curr_x, curr_y)]\n",
    "    idxs = [i for i in df_cpy.index]\n",
    "    items_per_cluster = [1 for i in range(0, len(curr_x))]\n",
    "    m = 2.00\n",
    "    n = len(df_cpy)\n",
    "    k = len(curr_clusters)\n",
    "    v = [np.std(normalized_df.iloc[:,i]) / np.average(normalized_df.iloc[:,i]) for i in range(0, len(normalized_df.columns))]\n",
    "    w = list(ewm(normalized_df)['weight'])\n",
    "    mat = initialize_membership_matrix(n, k)\n",
    "\n",
    "    while len(curr_clusters) > 1:\n",
    "        n = len(df_cpy)\n",
    "        k = len(curr_clusters)\n",
    "\n",
    "        mat = initialize_membership_matrix(n, k)\n",
    "        mat = update_membership_values_weighted(mat, curr_clusters, df_cpy, m, k, w)\n",
    "        for m in range(0, len(mat)):\n",
    "            mat[m][m] = 100\n",
    "        new_clusters = np.argwhere(mat == np.amin(mat))[0]\n",
    "        c1 = new_clusters[0]\n",
    "        c2 = new_clusters[1]\n",
    "        curr_dist = np.amin(mat)\n",
    "        print(f\"k {k} c1 {c1} c2 {c2} curr dist {curr_dist}\")\n",
    "\n",
    "        # Specify new cluster centroids\n",
    "        new_c = []\n",
    "        new_c.append((curr_clusters[c1][0] + curr_clusters[c2][0])/2)\n",
    "        new_c.append((curr_clusters[c1][1] + curr_clusters[c2][1])/2)\n",
    "\n",
    "        # Remove old clusters from the set of current clusters\n",
    "        curr_clusters.pop(c1)\n",
    "        curr_clusters.pop(c2-1)\n",
    "\n",
    "        # Drop old elements in dataframe\n",
    "        df_cpy = df_cpy.drop([c1, c2])\n",
    "        df_cpy = df_cpy.reset_index(drop=True)\n",
    "\n",
    "        # Add in new cluster to dataframe\n",
    "        df_cpy.loc[len(df_cpy)] = new_c\n",
    "\n",
    "        # Increment for new cluster\n",
    "        idxs.append(idxs[-1] + 1)\n",
    "\n",
    "        # Add new cluster to list of clusters\n",
    "        curr_clusters.append(new_c)\n",
    "\n",
    "        # Update number of items per cluster, removing old ones and adding in new one\n",
    "        num_items = items_per_cluster[c1] + items_per_cluster[c2]\n",
    "        items_per_cluster.pop(c1)\n",
    "        items_per_cluster.pop(c2-1)\n",
    "        items_per_cluster.append(num_items)\n",
    "\n",
    "        # Add new iteraion to linkage\n",
    "        fuzzy_linkage.append([idxs[c1], idxs[c2], curr_dist, num_items])\n",
    "\n",
    "        # Remove old cluster indices\n",
    "        if c2 > c1:\n",
    "            idxs.pop(c1)\n",
    "            idxs.pop(c2-1)\n",
    "        else:\n",
    "            idxs.pop(c2)\n",
    "            idxs.pop(c1-1)\n",
    "            \n",
    "    return fuzzy_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewm_fuzzy_linkage = hierarchical_clustering_linkage_ewm_weighted_fuzzy_membership_matrix(normalized_df)\n",
    "tpd = pd.DataFrame(ewm_fuzzy_linkage, \n",
    "             columns=['row label 1', 'row label 2', 'distance', 'no. of items in clust.'],\n",
    "             index=['cluster %d' %(i+1) for i in range(len(ewm_fuzzy_linkage))])\n",
    "tpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 10))\n",
    "row_dendr = dendrogram(ewm_fuzzy_linkage, labels=indices)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
